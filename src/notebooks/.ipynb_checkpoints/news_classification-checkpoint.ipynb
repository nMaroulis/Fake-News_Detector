{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, io, os, errno, fileinput, csv\n",
    "import collections as cl\n",
    "from os import path\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib as plt\n",
    "import seaborn as sb\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "import itertools\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "trainset_file = \"../../Datasets/train_1.csv\"\n",
    "train_df = pd.read_csv(trainset_file,  sep=',')\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english', lowercase=True, ngram_range=(1, 2))\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=False)\n",
    "# svd = TruncatedSVD(n_components=16384)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Data Normalzation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344665\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.dropna(subset=['text'])\n",
    "X = count_vect.fit_transform(train_df[0:9000]['text'].astype('U'))\n",
    "X = tfidf_transformer.fit_transform(X)\n",
    "# X = svd.fit_transform(X)\n",
    "Y = train_df[0:9000]['label']\n",
    "Y = Y.values\n",
    "print(np.size(X,1)) # 7651414 4404842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\"\"\" 10-Fold Cross Validation \"\"\"\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def cross_val(model):\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    i = 0\n",
    "    for train, test in kfold.split(X, Y):\n",
    "\n",
    "        _ = model.fit(X[train],Y[train]) # train\n",
    "        predicted = model.predict(X[test])\n",
    "        i += 1\n",
    "        cvscores.append(np.mean(predicted == Y[test]) * 100)\n",
    "        # precision += precision_score(test_Y, predicted, average='macro')\n",
    "        # recall += recall_score(test_Y, predicted, average='macro')\n",
    "        # f1_sc += f1_score(test_Y, predicted, average='macro')\n",
    "        print('iter ',str(i))\n",
    "    \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__MLP__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "lr_ = 0.0003 # learning rate\n",
    "l2_ = 0.0001 # l2 penalty\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64,64,64), activation='relu', solver='adam', alpha=l2_, batch_size='auto', learning_rate='constant', learning_rate_init=lr_, max_iter=150)\n",
    "cross_val(dt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Decision Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n",
      "iter  7\n",
      "iter  8\n",
      "iter  9\n",
      "iter  10\n",
      "89.27% (+/- 1.48%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "dt_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), n_estimators= 5)\n",
    "cross_val(dt_model)\n",
    "# dump(dt_model, '../../models/dt_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__SVM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n",
      "iter  7\n",
      "iter  8\n",
      "iter  9\n",
      "iter  10\n",
      "95.73% (+/- 0.72%)\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC(kernel='linear', C=1.05, decision_function_shape='ovr',cache_size=500) # 1.1 93.8\n",
    "cross_val(svm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Final Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/articleSVM.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "X = count_vect.fit_transform(train_df['text'].astype('U'))\n",
    "X = tfidf_transformer.fit_transform(X)\n",
    "Y = train_df['label']\n",
    "Y = Y.values\n",
    "\n",
    "final_svm = svm.SVC(kernel='linear', C=1.05, decision_function_shape='ovr',cache_size=500) # 1.1 93.8\n",
    "_ = final_svm.fit(X,Y) # train\n",
    "\n",
    "dump(final_svm, '../../models/articleSVM.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Final Model + Transformer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "final_svm_pip = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', lowercase=True, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "    ('svm', svm.SVC(kernel='linear', C=1.05, decision_function_shape='ovr',cache_size=500)), ])\n",
    "\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "XX = train_df['text'].astype('U')\n",
    "YY = train_df['label']\n",
    "YY = YY.values\n",
    "\n",
    "_ = final_svm_pip.fit(XX,YY) # train\n",
    "\n",
    "#dump(final_svm_pip, '../../models/articleSVM.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "___TEST___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8a7132c1335b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" 10-Fold Cross Validation \"\"\"\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "svm_max = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=200, stop_words='english', lowercase=True,ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "    ('svm', svm.SVC(kernel='linear', C=1.05, decision_function_shape='ovr',cache_size=500)), ])\n",
    "\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "X = train_df['text'].values.astype('U')\n",
    "Y = train_df['label']\n",
    "Y = Y.values\n",
    "\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "i = 0\n",
    "for train, test in kfold.split(X, Y):\n",
    "\n",
    "    _ = svm_max.fit(X[train],Y[train]) # train\n",
    "    predicted = svm_max.predict(X[test])\n",
    "    i += 1\n",
    "    cvscores.append(np.mean(predicted == Y[test]) * 100)\n",
    "    print('iter ',str(i))\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n",
      "iter  7\n",
      "iter  8\n",
      "iter  9\n",
      "iter  10\n",
      "99.97% (+/- 0.03%)\n"
     ]
    }
   ],
   "source": [
    "XX = XX.values\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "i = 0\n",
    "for train, test in kfold.split(XX, YY):\n",
    "    predicted = final_svm_pip.predict(XX[test])\n",
    "    i += 1\n",
    "    cvscores.append(np.mean(predicted == YY[test]) * 100)\n",
    "    print('iter ',str(i))\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Tensorflow Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 2048)              9021118464\n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 9,027,414,017\n",
      "Trainable params: 9,027,414,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "layer1 = [ 8 , 16 , 32 , 64 , 128 , 128 , 64 , 32 , 16 , 8 ]\n",
    "layer2 = [ 16 , 16 , 32 , 16 , 16 , 8 , 16 , 32 , 64 , 128 ]\n",
    "\n",
    "kmodel = kr.models.Sequential()\n",
    "kmodel.add(kr.layers.Dense(2048, input_dim=np.size(X,1), activation='relu'))\n",
    "kmodel.add(kr.layers.Dense(2048, activation='relu'))\n",
    "kmodel.add(kr.layers.Dense(1024, activation='relu'))\n",
    "kmodel.add(kr.layers.Dense(1, activation='sigmoid'))\n",
    "kmodel.summary()\n",
    "#adam_opt = kr.optimizers.Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "kmodel.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# kmodel.fit(X,Y, epochs=1000, batch_size=10, verbose=1, shuffle=True, class_weight=None, sample_weight=None) # train\n",
    "\n",
    "i = 0\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    kmodel.fit(X[train],Y[train], epochs=100, batch_size=10, verbose=0, shuffle=True, class_weight=None, sample_weight=None) # train\n",
    "\n",
    "    i += 1\n",
    "    scores = kmodel.evaluate(X[test], Y[test], verbose=0)\n",
    "    \n",
    "    print(\"<%d> %s: %.2f%%\" %  (i,kmodel.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Classification with Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n",
      "iter  7\n",
      "iter  8\n",
      "iter  9\n",
      "iter  10\n",
      "88.10% (+/- 2.08%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\"\"\" number of decision trees: 240\n",
    "    max_depth in tree: 30\"\"\"\n",
    "random_forest_bow = RandomForestClassifier(n_estimators=240, max_depth=30, random_state=0)\n",
    "cross_val(random_forest_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__Classification with Naive Bayes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n",
      "iter  7\n",
      "iter  8\n",
      "iter  9\n",
      "iter  10\n",
      "82.96% (+/- 2.20%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(fit_prior=False)\n",
    "cross_val(nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
